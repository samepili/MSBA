{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis - HW2\n",
    "Samir Epili - se7982 - 8:30-10:30 section\n",
    "\n",
    "Christian Lee - cnl878 - 10:30-12:30 section\n",
    "\n",
    "Dylan Nikol - drn497 - 10:30-12:30 section\n",
    "\n",
    "Luke Stevens - ls44426 - 8:30-10:30 section\n",
    "\n",
    "Matthew Streichler - mrs4732 - 10:30-12:30 section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task A\n",
    "Extract 5-6K reviews of 200-250 products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'')\n",
    "from selenium import webdriver\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def altElement(l):\n",
    "    return l[::2]\n",
    "\n",
    "# removes extra data that comes with each comment\n",
    "def split_comment(s):\n",
    "    splitted = s.split('\\n')\n",
    "    comment_body = splitted[5:-2]\n",
    "    return comment_body\n",
    "\n",
    "# converts comments to a string and removes brackets\n",
    "def list_to_string(x):\n",
    "    string = str(x)\n",
    "    return string.rstrip(']').lstrip('[')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "driver = webdriver.Chrome('C:\\\\Users\\\\samir\\\\Documents\\\\chromedriver_win32\\\\chromedriver.exe', options=chrome_options)\n",
    "driver.get('https://www.beeradvocate.com/beer/top-rated/')\n",
    "urls = []\n",
    "beer_names = []\n",
    "\n",
    "# Get list of beer urls\n",
    "url_paths = driver.find_elements_by_xpath('//*[contains(@href, \"/beer/profile/\")]')\n",
    "for i in url_paths:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "beer_urls = altElement(urls)\n",
    "\n",
    "# Get list of beer names\n",
    "beer_name = driver.find_elements_by_xpath('//*[contains(@href, \"/beer/profile/\")]')\n",
    "for i in beer_name:\n",
    "    beer_names.append(i.text)\n",
    "beer_names = altElement(beer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beer data exported to beer.csv :)\n"
     ]
    }
   ],
   "source": [
    "# scrape comments for each beer\n",
    "beer = pd.DataFrame(columns = ['product_name','product_review','user_rating'])\n",
    "\n",
    "\n",
    "for beer_page in beer_urls:\n",
    "    driver.get(beer_page)\n",
    "    ids = driver.find_elements_by_xpath(\"//*[contains(@id,'rating_fullview_container')]\")\n",
    "    comment_ids = []\n",
    "    for i in ids:\n",
    "        comment_ids.append(i.get_attribute('ba-user'))\n",
    "\n",
    "    for x in comment_ids:\n",
    "        \n",
    "        product_name = driver.find_elements_by_xpath('//*[@id=\"content\"]/div/div/div[3]/div/div/div[1]/h1')[0]\n",
    "        product = product_name.text.split('\\n')[0]\n",
    "\n",
    "        user_message = driver.find_elements_by_xpath('//*[@ba-user= ' + x + ']')[0]\n",
    "        comment = user_message.text\n",
    "\n",
    "        user_rating = driver.find_elements_by_xpath('//*[@ba-user= ' + x + ']//*[@id=\"rating_fullview_content_2\"]/span[2]')[0]\n",
    "        rating = user_rating.text\n",
    "\n",
    "        beer.loc[len(beer)] = [product,comment,rating]\n",
    "\n",
    "beer['product_review'] = beer['product_review'].map(split_comment)\n",
    "beer['product_review'] = beer['product_review'].map(list_to_string)\n",
    "\n",
    "beer.to_csv('beer.csv')\n",
    "print(\"Beer data exported to beer.csv :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "\n",
    "df = pd.read_csv('beer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_review</th>\n",
       "      <th>user_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>'2019 draft and bottle.', '', \"I didn't think ...</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>'Smell: early morning pancakes and coffee befo...</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>\"2019 vintage. Pours a very dark brown color w...</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>\"It's hyped... There is a lot of breweries doi...</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>\"Reviewing 2019 vintage. This pours thick and ...</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product_name  \\\n",
       "0  Kentucky Brunch Brand Stout   \n",
       "1  Kentucky Brunch Brand Stout   \n",
       "2  Kentucky Brunch Brand Stout   \n",
       "3  Kentucky Brunch Brand Stout   \n",
       "4  Kentucky Brunch Brand Stout   \n",
       "\n",
       "                                      product_review  user_rating  \n",
       "0  '2019 draft and bottle.', '', \"I didn't think ...         4.99  \n",
       "1  'Smell: early morning pancakes and coffee befo...         5.00  \n",
       "2  \"2019 vintage. Pours a very dark brown color w...         4.53  \n",
       "3  \"It's hyped... There is a lot of breweries doi...         1.49  \n",
       "4  \"Reviewing 2019 vintage. This pours thick and ...         4.52  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    '2019 draft and bottle.', '', \"I didn't think ...\n",
       "1    'Smell: early morning pancakes and coffee befo...\n",
       "2    \"2019 vintage. Pours a very dark brown color w...\n",
       "3    \"It's hyped... There is a lot of breweries doi...\n",
       "4    \"Reviewing 2019 vintage. This pours thick and ...\n",
       "Name: product_review, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = df.product_review\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B\n",
    "We assume that the customer has chosen the following attributes to describe a beer - complex, spicy, aroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_atts = ['complex', 'spicy', 'aroma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task C\n",
    "Perform cosine similarity analysis with three attributes - output product_name, product_review, similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim\n",
    "#!pip install translate\n",
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import string\n",
    "from string import punctuation\n",
    "import translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words_remover(review):\n",
    "    review = remove_stopwords(review)\n",
    "    return review\n",
    "\n",
    "def combine(review):\n",
    "    return \"\".join(review)\n",
    "\n",
    "def cos_sim(review):\n",
    "    orig_atts = \" \".join(original_atts)\n",
    "    review_att = [orig_atts, review]\n",
    "    tfidf_vec = TfidfVectorizer()\n",
    "    tfidf = tfidf_vec.fit_transform(review_att)\n",
    "    return cosine_similarity(tfidf[0:1], tfidf)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_df = pd.DataFrame(data=df[[\"product_name\", \"product_review\", \"user_rating\"]])\n",
    "\n",
    "cos_df[\"new_comment\"] = df['product_review'].apply(lambda x : str(x).translate(str.maketrans('', '', string.punctuation)))\n",
    "cos_df['new_comment'] = cos_df[\"new_comment\"].map(stop_words_remover)\n",
    "cos_df['new_comment'] = cos_df[\"new_comment\"].map(combine)\n",
    "cos_df['cos_sim'] = cos_df[\"new_comment\"].map(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_review</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>2019 draft bottle I didnt think beer possibly ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>Smell early morning pancakes coffee work wakes...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>2019 vintage Pours dark brown color noticeable...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>Its hyped There lot breweries style beer right...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>Reviewing 2019 vintage This pours close black ...</td>\n",
       "      <td>0.034786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6225</td>\n",
       "      <td>Scaled Up</td>\n",
       "      <td>Look Hazy pale gold With white head Mild activ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6226</td>\n",
       "      <td>Scaled Up</td>\n",
       "      <td>Cloudy like Trillium unfiltered beers The colo...</td>\n",
       "      <td>0.032721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6227</td>\n",
       "      <td>Scaled Up</td>\n",
       "      <td>Pale golden head small lacing Aromas intense g...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6228</td>\n",
       "      <td>Scaled Up</td>\n",
       "      <td>This better beers ive I privilege enjoying lar...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6229</td>\n",
       "      <td>Scaled Up</td>\n",
       "      <td>I told closest hop profile Headroom I try If h...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6230 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     product_name  \\\n",
       "0     Kentucky Brunch Brand Stout   \n",
       "1     Kentucky Brunch Brand Stout   \n",
       "2     Kentucky Brunch Brand Stout   \n",
       "3     Kentucky Brunch Brand Stout   \n",
       "4     Kentucky Brunch Brand Stout   \n",
       "...                           ...   \n",
       "6225                    Scaled Up   \n",
       "6226                    Scaled Up   \n",
       "6227                    Scaled Up   \n",
       "6228                    Scaled Up   \n",
       "6229                    Scaled Up   \n",
       "\n",
       "                                         product_review  similarity_score  \n",
       "0     2019 draft bottle I didnt think beer possibly ...          0.000000  \n",
       "1     Smell early morning pancakes coffee work wakes...          0.000000  \n",
       "2     2019 vintage Pours dark brown color noticeable...          0.000000  \n",
       "3     Its hyped There lot breweries style beer right...          0.000000  \n",
       "4     Reviewing 2019 vintage This pours close black ...          0.034786  \n",
       "...                                                 ...               ...  \n",
       "6225  Look Hazy pale gold With white head Mild activ...          0.000000  \n",
       "6226  Cloudy like Trillium unfiltered beers The colo...          0.032721  \n",
       "6227  Pale golden head small lacing Aromas intense g...          0.000000  \n",
       "6228  This better beers ive I privilege enjoying lar...          0.000000  \n",
       "6229  I told closest hop profile Headroom I try If h...          0.000000  \n",
       "\n",
       "[6230 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_c_df = pd.DataFrame(data=cos_df[[\"product_name\", \"new_comment\", \"cos_sim\"]])\n",
    "task_c_df.rename(columns={\"new_comment\":\"product_review\", \"cos_sim\":\"similarity_score\"}, inplace=True)\n",
    "task_c_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task D\n",
    "Perform sentiment analysis for each attribute - output sentinment score for individual attributes and average sentiment score of all three attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function version of above to find all variations of three selected attributes\n",
    "import re\n",
    "\n",
    "def update_list(attribute_list):\n",
    "    match_list = []\n",
    "    for i in reviews:\n",
    "        for att in attribute_list:\n",
    "            match = re.findall(att + '[?!.,]+', str(i))\n",
    "            if match not in match_list and match != []:\n",
    "                match_list.append(match)\n",
    "                for x in match_list:\n",
    "                    for y in x:\n",
    "                        attribute_list.append(y)\n",
    "    return set(attribute_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install if necessary\n",
    "#!pip install vaderSentiment\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = SentimentIntensityAnalyzer(lexicon_file=\"vader_lexicon_beer.txt\", \\\n",
    "                                 emoji_lexicon=\"emoji_utf8_lexicon.txt\")\n",
    "\n",
    "#lexicon used is different from the default lexicon\n",
    "## changed hell -> 0.0, dangerously -> 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = lex.polarity_scores(sentence)\n",
    "    #print(\"{:-<40} {}\".format(sentence, str(score)))\n",
    "    #return compound score only to add to DF\n",
    "    comp = score['compound']\n",
    "    return comp\n",
    "\n",
    "def att_to_dict(attribute_list):\n",
    "    att_dict = dict.fromkeys(attribute_list, 0)\n",
    "    return att_dict\n",
    "\n",
    "def add_to_dict(att, original_atts, att_dict):\n",
    "    if att in original_atts:\n",
    "        att_dict[att] += 1\n",
    "    return att_dict        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call list function to find all attributes with punctuation\n",
    "att = update_list(original_atts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call list function to find all attributes with punctuation\n",
    "original_atts = ['complex', 'spicy', 'aroma']\n",
    "\n",
    "score_list = []\n",
    "\n",
    "att_scores_df = pd.DataFrame(columns = original_atts)\n",
    "\n",
    "\n",
    "for phrase in reviews:\n",
    "    #create dictionary from original attribute list to keep track of composite scores for each attribute per review\n",
    "    att_scores = att_to_dict(original_atts)\n",
    "    \n",
    "    score = 0\n",
    "    count = 0\n",
    "    att1_count = 0\n",
    "    att2_count = 0\n",
    "    att3_count = 0\n",
    "    arr = str(phrase).replace(\"'\",'').split()\n",
    "    its = [iter(arr), iter(arr[1:]), iter(arr[2:]), iter(arr[3:]), iter(arr[4:])]\n",
    "    parse = list(zip(its[0], its[1], its[2], its[3], its[4]))\n",
    "    for i in range(len(parse)):\n",
    "        if i == 0:\n",
    "            if parse[i][0] in att:\n",
    "                #print(parse[i][0])\n",
    "                #print(sentiment_analyzer_scores(' '.join(parse[i])))\n",
    "                score += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                count += 1        \n",
    "                if original_atts[0] in parse[i][0]:\n",
    "                    att_scores[original_atts[0]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                    att1_count += 1\n",
    "                if original_atts[1] in parse[i][0]:\n",
    "                    att_scores[original_atts[1]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                    att2_count += 1\n",
    "                if original_atts[2] in parse[i][0]:\n",
    "                    att_scores[original_atts[2]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                    att3_count += 1                                    \n",
    "            if parse[i][1] in att:\n",
    "                #print(parse[i][1])\n",
    "                #print(sentiment_analyzer_scores(' '.join(parse[i])))\n",
    "                score += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                count += 1\n",
    "                if original_atts[0] in parse[i][1]:\n",
    "                    att_scores[original_atts[0]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                    att1_count += 1\n",
    "                if original_atts[1] in parse[i][1]:\n",
    "                    att_scores[original_atts[1]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                    att2_count += 1\n",
    "                if original_atts[2] in parse[i][1]:\n",
    "                    att_scores[original_atts[2]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                    att3_count += 1\n",
    "                    \n",
    "        if i == len(parse)-1:\n",
    "            if parse[i][3] in att:\n",
    "                #print(parse[i][3])\n",
    "                #print(sentiment_analyzer_scores(' '.join(parse[i])))\n",
    "                score += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                count += 1\n",
    "                if original_atts[0] in parse[i][3]:\n",
    "                    att_scores[original_atts[0]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                    att1_count += 1\n",
    "                if original_atts[1] in parse[i][3]:\n",
    "                    att_scores[original_atts[1]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                    att2_count += 1\n",
    "                if original_atts[2] in parse[i][3]:\n",
    "                    att_scores[original_atts[2]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                    att3_count += 1\n",
    "            if parse[i][4] in att:\n",
    "                #print(parse[i][4])\n",
    "                #print(sentiment_analyzer_scores(' '.join(parse[i])))\n",
    "                score += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                count += 1\n",
    "                if original_atts[0] in parse[i][4]:\n",
    "                    att_scores[original_atts[0]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                    att1_count += 1\n",
    "                if original_atts[1] in parse[i][4]:\n",
    "                    att_scores[original_atts[1]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                    att2_count += 1\n",
    "                if original_atts[2] in parse[i][4]:\n",
    "                    att_scores[original_atts[2]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                    att3_count += 1\n",
    "        if parse[i][2] in att:\n",
    "            #print(parse[i][2])\n",
    "            #print(sentiment_analyzer_scores(' '.join(parse[i])))\n",
    "            score += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "            count += 1\n",
    "            if original_atts[0] in parse[i][2]:\n",
    "                att_scores[original_atts[0]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                att1_count += 1\n",
    "            if original_atts[1] in parse[i][2]:\n",
    "                att_scores[original_atts[1]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                att2_count += 1\n",
    "            if original_atts[2] in parse[i][2]:\n",
    "                att_scores[original_atts[2]] += sentiment_analyzer_scores(' '.join(parse[i]))\n",
    "                att3_count += 1\n",
    "    \n",
    "    if att1_count == 0:\n",
    "        att_scores[original_atts[0]] = np.nan\n",
    "    else:\n",
    "        att_scores[original_atts[0]] = att_scores[original_atts[0]]/att1_count\n",
    "    if att2_count == 0:\n",
    "        att_scores[original_atts[1]] = np.nan\n",
    "    else:\n",
    "        att_scores[original_atts[1]] = att_scores[original_atts[1]]/att2_count\n",
    "    if att3_count == 0:\n",
    "        att_scores[original_atts[2]] = np.nan\n",
    "    else:\n",
    "        att_scores[original_atts[2]] = att_scores[original_atts[2]]/att3_count\n",
    "        \n",
    "    att_scores_df = att_scores_df.append(att_scores, ignore_index = True)\n",
    "    \n",
    "    if count == 0:\n",
    "        score_list.append(np.nan)\n",
    "        \n",
    "    else:\n",
    "        score_list.append(score/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn overall_sent_score into Series to append to beer DF\n",
    "df['overall_sent_score'] = pd.Series(score_list)\n",
    "\n",
    "# merge df with att_scores_df\n",
    "beer_sent = df.merge(att_scores_df, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_rating</th>\n",
       "      <th>overall_sent_score</th>\n",
       "      <th>complex</th>\n",
       "      <th>spicy</th>\n",
       "      <th>aroma</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Headroom</td>\n",
       "      <td>4.5168</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pirate Bomb!</td>\n",
       "      <td>4.4632</td>\n",
       "      <td>0.649175</td>\n",
       "      <td>0.59450</td>\n",
       "      <td>0.641150</td>\n",
       "      <td>0.70470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pseudo Sue - Double Dry-Hopped</td>\n",
       "      <td>4.3156</td>\n",
       "      <td>0.527350</td>\n",
       "      <td>0.42150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.54852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Black Tuesday - Reserve</td>\n",
       "      <td>4.5880</td>\n",
       "      <td>0.499825</td>\n",
       "      <td>0.65605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fou' Foune</td>\n",
       "      <td>4.5068</td>\n",
       "      <td>0.496250</td>\n",
       "      <td>0.59940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.47562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Cellarman Barrel Aged Saison</td>\n",
       "      <td>4.4576</td>\n",
       "      <td>-0.034233</td>\n",
       "      <td>-0.05135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Very Hazy</td>\n",
       "      <td>4.6944</td>\n",
       "      <td>-0.070250</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.140500</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fuzzy Baby Ducks</td>\n",
       "      <td>4.3100</td>\n",
       "      <td>-0.084300</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.14050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ghost In The Machine - Double Dry-Hopped</td>\n",
       "      <td>4.5044</td>\n",
       "      <td>-0.093380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>-0.23835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Heavy Mettle</td>\n",
       "      <td>4.3500</td>\n",
       "      <td>-0.142600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.14260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_rating  overall_sent_score  \\\n",
       "product_name                                                                \n",
       "Headroom                                       4.5168            0.750100   \n",
       "Pirate Bomb!                                   4.4632            0.649175   \n",
       "Pseudo Sue - Double Dry-Hopped                 4.3156            0.527350   \n",
       "Black Tuesday - Reserve                        4.5880            0.499825   \n",
       "Fou' Foune                                     4.5068            0.496250   \n",
       "...                                               ...                 ...   \n",
       "Cellarman Barrel Aged Saison                   4.4576           -0.034233   \n",
       "Very Hazy                                      4.6944           -0.070250   \n",
       "Fuzzy Baby Ducks                               4.3100           -0.084300   \n",
       "Ghost In The Machine - Double Dry-Hopped       4.5044           -0.093380   \n",
       "Heavy Mettle                                   4.3500           -0.142600   \n",
       "\n",
       "                                          complex     spicy    aroma  \n",
       "product_name                                                          \n",
       "Headroom                                      NaN       NaN  0.75010  \n",
       "Pirate Bomb!                              0.59450  0.641150  0.70470  \n",
       "Pseudo Sue - Double Dry-Hopped            0.42150       NaN  0.54852  \n",
       "Black Tuesday - Reserve                   0.65605       NaN  0.00000  \n",
       "Fou' Foune                                0.59940       NaN  0.47562  \n",
       "...                                           ...       ...      ...  \n",
       "Cellarman Barrel Aged Saison             -0.05135       NaN  0.00000  \n",
       "Very Hazy                                 0.00000 -0.140500  0.00000  \n",
       "Fuzzy Baby Ducks                          0.00000  0.000000 -0.14050  \n",
       "Ghost In The Machine - Double Dry-Hopped      NaN  0.003267 -0.23835  \n",
       "Heavy Mettle                                  NaN       NaN -0.14260  \n",
       "\n",
       "[250 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beer_sent.groupby(['product_name']).mean().sort_values(by = 'overall_sent_score', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task E\n",
    "Assume an evaluation score for each beer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>overall_sent_score</th>\n",
       "      <th>complex</th>\n",
       "      <th>spicy</th>\n",
       "      <th>aroma</th>\n",
       "      <th>Recommendation_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_name_x</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Leche Borracho</td>\n",
       "      <td>0.038135</td>\n",
       "      <td>4.4756</td>\n",
       "      <td>0.179663</td>\n",
       "      <td>0.130750</td>\n",
       "      <td>0.19765</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>3.650484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fou' Foune</td>\n",
       "      <td>0.020253</td>\n",
       "      <td>4.5068</td>\n",
       "      <td>0.496250</td>\n",
       "      <td>0.599400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.475620</td>\n",
       "      <td>3.570030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zenne Y Frontera</td>\n",
       "      <td>0.027919</td>\n",
       "      <td>4.6968</td>\n",
       "      <td>0.347070</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.270925</td>\n",
       "      <td>3.491799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Oude Geuze Cuvée Armand &amp; Gaston</td>\n",
       "      <td>0.036483</td>\n",
       "      <td>4.4664</td>\n",
       "      <td>0.177522</td>\n",
       "      <td>0.079017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.305840</td>\n",
       "      <td>3.380266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pirate Bomb!</td>\n",
       "      <td>0.010105</td>\n",
       "      <td>4.4632</td>\n",
       "      <td>0.649175</td>\n",
       "      <td>0.594500</td>\n",
       "      <td>0.64115</td>\n",
       "      <td>0.704700</td>\n",
       "      <td>3.300493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Assassin</td>\n",
       "      <td>0.005486</td>\n",
       "      <td>4.5012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.842462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jam The Radar</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>4.5616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.862724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Marshmallow Handjee</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>4.7016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.206529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Heavy Mettle</td>\n",
       "      <td>0.009905</td>\n",
       "      <td>4.3500</td>\n",
       "      <td>-0.142600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.142600</td>\n",
       "      <td>-3.361661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SR-71</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>4.7464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.449465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  similarity_score  user_rating  \\\n",
       "product_name_x                                                    \n",
       "Leche Borracho                            0.038135       4.4756   \n",
       "Fou' Foune                                0.020253       4.5068   \n",
       "Zenne Y Frontera                          0.027919       4.6968   \n",
       "Oude Geuze Cuvée Armand & Gaston          0.036483       4.4664   \n",
       "Pirate Bomb!                              0.010105       4.4632   \n",
       "...                                            ...          ...   \n",
       "Assassin                                  0.005486       4.5012   \n",
       "Jam The Radar                             0.005353       4.5616   \n",
       "Marshmallow Handjee                       0.003103       4.7016   \n",
       "Heavy Mettle                              0.009905       4.3500   \n",
       "SR-71                                     0.001513       4.7464   \n",
       "\n",
       "                                  overall_sent_score   complex    spicy  \\\n",
       "product_name_x                                                            \n",
       "Leche Borracho                              0.179663  0.130750  0.19765   \n",
       "Fou' Foune                                  0.496250  0.599400      NaN   \n",
       "Zenne Y Frontera                            0.347070  0.341000      NaN   \n",
       "Oude Geuze Cuvée Armand & Gaston            0.177522  0.079017      NaN   \n",
       "Pirate Bomb!                                0.649175  0.594500  0.64115   \n",
       "...                                              ...       ...      ...   \n",
       "Assassin                                    0.000000  0.000000      NaN   \n",
       "Jam The Radar                               0.000000       NaN      NaN   \n",
       "Marshmallow Handjee                         0.000000       NaN      NaN   \n",
       "Heavy Mettle                               -0.142600       NaN      NaN   \n",
       "SR-71                                       0.000000       NaN      NaN   \n",
       "\n",
       "                                     aroma  Recommendation_Score  \n",
       "product_name_x                                                    \n",
       "Leche Borracho                    0.155400              3.650484  \n",
       "Fou' Foune                        0.475620              3.570030  \n",
       "Zenne Y Frontera                  0.270925              3.491799  \n",
       "Oude Geuze Cuvée Armand & Gaston  0.305840              3.380266  \n",
       "Pirate Bomb!                      0.704700              3.300493  \n",
       "...                                    ...                   ...  \n",
       "Assassin                          0.000000             -2.842462  \n",
       "Jam The Radar                     0.000000             -2.862724  \n",
       "Marshmallow Handjee               0.000000             -3.206529  \n",
       "Heavy Mettle                     -0.142600             -3.361661  \n",
       "SR-71                             0.000000             -3.449465  \n",
       "\n",
       "[250 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "agg_all_recs = task_c_df.merge(beer_sent, left_index = True, right_index = True)\n",
    "all_recs_by_beer = agg_all_recs.groupby(['product_name_x']).mean()\n",
    "\n",
    "scale = sklearn.preprocessing.scale\n",
    "all_recs_by_beer['Recommendation_Score'] = scale(all_recs_by_beer['similarity_score']) + scale(all_recs_by_beer['overall_sent_score'])\n",
    "\n",
    "result = all_recs_by_beer.sort_values(by='Recommendation_Score', ascending=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scaled similarity_score and overall_sent_score because a beer might have a low similarity and a high sentiment on 1 attribute which would output a higher recommendation score than what it should actually have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>overall_sent_score</th>\n",
       "      <th>complex</th>\n",
       "      <th>spicy</th>\n",
       "      <th>aroma</th>\n",
       "      <th>Recommendation_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_name_x</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Leche Borracho</td>\n",
       "      <td>0.038135</td>\n",
       "      <td>4.4756</td>\n",
       "      <td>0.179663</td>\n",
       "      <td>0.13075</td>\n",
       "      <td>0.19765</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>3.650484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fou' Foune</td>\n",
       "      <td>0.020253</td>\n",
       "      <td>4.5068</td>\n",
       "      <td>0.496250</td>\n",
       "      <td>0.59940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.475620</td>\n",
       "      <td>3.570030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zenne Y Frontera</td>\n",
       "      <td>0.027919</td>\n",
       "      <td>4.6968</td>\n",
       "      <td>0.347070</td>\n",
       "      <td>0.34100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.270925</td>\n",
       "      <td>3.491799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  similarity_score  user_rating  overall_sent_score  complex  \\\n",
       "product_name_x                                                                 \n",
       "Leche Borracho            0.038135       4.4756            0.179663  0.13075   \n",
       "Fou' Foune                0.020253       4.5068            0.496250  0.59940   \n",
       "Zenne Y Frontera          0.027919       4.6968            0.347070  0.34100   \n",
       "\n",
       "                    spicy     aroma  Recommendation_Score  \n",
       "product_name_x                                             \n",
       "Leche Borracho    0.19765  0.155400              3.650484  \n",
       "Fou' Foune            NaN  0.475620              3.570030  \n",
       "Zenne Y Frontera      NaN  0.270925              3.491799  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend that the a customer try the following three beers if they searched for complex, spicy, and aroma:\n",
    "    1. Zenne Y Frontera\n",
    "    2. Leche Borracho\n",
    "    3. Fou' Foune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "\n",
    "def spacy_sim(review):\n",
    "    r = nlp(review)\n",
    "    orig_atts = \" \".join(original_atts)\n",
    "    sp_sim = nlp(orig_atts)\n",
    "    return r.similarity(sp_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_review</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>spacy_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>2019 draft bottle I didnt think beer possibly ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>Smell early morning pancakes coffee work wakes...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>2019 vintage Pours dark brown color noticeable...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.721600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>Its hyped There lot breweries style beer right...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>Reviewing 2019 vintage This pours close black ...</td>\n",
       "      <td>0.034786</td>\n",
       "      <td>0.616807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6225</td>\n",
       "      <td>Scaled Up</td>\n",
       "      <td>Look Hazy pale gold With white head Mild activ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.771640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6226</td>\n",
       "      <td>Scaled Up</td>\n",
       "      <td>Cloudy like Trillium unfiltered beers The colo...</td>\n",
       "      <td>0.032721</td>\n",
       "      <td>0.747522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6227</td>\n",
       "      <td>Scaled Up</td>\n",
       "      <td>Pale golden head small lacing Aromas intense g...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.738758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6228</td>\n",
       "      <td>Scaled Up</td>\n",
       "      <td>This better beers ive I privilege enjoying lar...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.580004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6229</td>\n",
       "      <td>Scaled Up</td>\n",
       "      <td>I told closest hop profile Headroom I try If h...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6230 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     product_name  \\\n",
       "0     Kentucky Brunch Brand Stout   \n",
       "1     Kentucky Brunch Brand Stout   \n",
       "2     Kentucky Brunch Brand Stout   \n",
       "3     Kentucky Brunch Brand Stout   \n",
       "4     Kentucky Brunch Brand Stout   \n",
       "...                           ...   \n",
       "6225                    Scaled Up   \n",
       "6226                    Scaled Up   \n",
       "6227                    Scaled Up   \n",
       "6228                    Scaled Up   \n",
       "6229                    Scaled Up   \n",
       "\n",
       "                                         product_review  similarity_score  \\\n",
       "0     2019 draft bottle I didnt think beer possibly ...          0.000000   \n",
       "1     Smell early morning pancakes coffee work wakes...          0.000000   \n",
       "2     2019 vintage Pours dark brown color noticeable...          0.000000   \n",
       "3     Its hyped There lot breweries style beer right...          0.000000   \n",
       "4     Reviewing 2019 vintage This pours close black ...          0.034786   \n",
       "...                                                 ...               ...   \n",
       "6225  Look Hazy pale gold With white head Mild activ...          0.000000   \n",
       "6226  Cloudy like Trillium unfiltered beers The colo...          0.032721   \n",
       "6227  Pale golden head small lacing Aromas intense g...          0.000000   \n",
       "6228  This better beers ive I privilege enjoying lar...          0.000000   \n",
       "6229  I told closest hop profile Headroom I try If h...          0.000000   \n",
       "\n",
       "      spacy_similarity  \n",
       "0             0.658769  \n",
       "1             0.660525  \n",
       "2             0.721600  \n",
       "3             0.476465  \n",
       "4             0.616807  \n",
       "...                ...  \n",
       "6225          0.771640  \n",
       "6226          0.747522  \n",
       "6227          0.738758  \n",
       "6228          0.580004  \n",
       "6229          0.540490  \n",
       "\n",
       "[6230 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_c_df['spacy_similarity'] = task_c_df['product_review'].apply(spacy_sim)\n",
    "task_c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name\n",
       "3rd Anniversary Imperial IPA               0.688106\n",
       "4th Anniversary                            0.681356\n",
       "A Deal With The Devil                      0.692171\n",
       "A Deal With The Devil - Double Oak-Aged    0.662109\n",
       "Aaron                                      0.704239\n",
       "                                             ...   \n",
       "Westly                                     0.677065\n",
       "Wide Awake It's Morning                    0.706549\n",
       "Zenne Y Frontera                           0.714518\n",
       "Zombie Dust                                0.704671\n",
       "§ucaba                                     0.710032\n",
       "Name: spacy_similarity, Length: 250, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_by_beer = task_c_df.groupby(['product_name']).mean()['spacy_similarity']\n",
    "spacy_by_beer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>spacy_similarity</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>overall_sent_score</th>\n",
       "      <th>Recommendation_Score</th>\n",
       "      <th>Recommendation_Score_Spacy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_name_x</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Headroom</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689513</td>\n",
       "      <td>4.5168</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>2.601863</td>\n",
       "      <td>4.856284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pirate Bomb!</td>\n",
       "      <td>0.010105</td>\n",
       "      <td>0.689698</td>\n",
       "      <td>4.4632</td>\n",
       "      <td>0.649175</td>\n",
       "      <td>3.300493</td>\n",
       "      <td>4.019034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fou' Foune</td>\n",
       "      <td>0.020253</td>\n",
       "      <td>0.712967</td>\n",
       "      <td>4.5068</td>\n",
       "      <td>0.496250</td>\n",
       "      <td>3.570030</td>\n",
       "      <td>3.751929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Abraxas</td>\n",
       "      <td>0.019852</td>\n",
       "      <td>0.742988</td>\n",
       "      <td>4.4980</td>\n",
       "      <td>0.283637</td>\n",
       "      <td>1.728113</td>\n",
       "      <td>3.279064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Stickee Monkee</td>\n",
       "      <td>0.027935</td>\n",
       "      <td>0.730127</td>\n",
       "      <td>4.5376</td>\n",
       "      <td>0.277220</td>\n",
       "      <td>2.909255</td>\n",
       "      <td>2.665019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Assassin</td>\n",
       "      <td>0.005486</td>\n",
       "      <td>0.658370</td>\n",
       "      <td>4.5012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.842462</td>\n",
       "      <td>-2.782919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Resolute - Coconut</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>0.635304</td>\n",
       "      <td>4.6032</td>\n",
       "      <td>0.114967</td>\n",
       "      <td>-1.819826</td>\n",
       "      <td>-2.824905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pliny The Elder</td>\n",
       "      <td>0.008355</td>\n",
       "      <td>0.624873</td>\n",
       "      <td>4.6092</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>-1.769268</td>\n",
       "      <td>-3.607345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Marshmallow Handjee</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.637519</td>\n",
       "      <td>4.7016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.206529</td>\n",
       "      <td>-3.691288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SR-71</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.605507</td>\n",
       "      <td>4.7464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.449465</td>\n",
       "      <td>-5.085911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     similarity_score  spacy_similarity  user_rating  \\\n",
       "product_name_x                                                         \n",
       "Headroom                     0.000000          0.689513       4.5168   \n",
       "Pirate Bomb!                 0.010105          0.689698       4.4632   \n",
       "Fou' Foune                   0.020253          0.712967       4.5068   \n",
       "Abraxas                      0.019852          0.742988       4.4980   \n",
       "Stickee Monkee               0.027935          0.730127       4.5376   \n",
       "...                               ...               ...          ...   \n",
       "Assassin                     0.005486          0.658370       4.5012   \n",
       "Resolute - Coconut           0.005877          0.635304       4.6032   \n",
       "Pliny The Elder              0.008355          0.624873       4.6092   \n",
       "Marshmallow Handjee          0.003103          0.637519       4.7016   \n",
       "SR-71                        0.001513          0.605507       4.7464   \n",
       "\n",
       "                     overall_sent_score  Recommendation_Score  \\\n",
       "product_name_x                                                  \n",
       "Headroom                       0.750100              2.601863   \n",
       "Pirate Bomb!                   0.649175              3.300493   \n",
       "Fou' Foune                     0.496250              3.570030   \n",
       "Abraxas                        0.283637              1.728113   \n",
       "Stickee Monkee                 0.277220              2.909255   \n",
       "...                                 ...                   ...   \n",
       "Assassin                       0.000000             -2.842462   \n",
       "Resolute - Coconut             0.114967             -1.819826   \n",
       "Pliny The Elder                0.075800             -1.769268   \n",
       "Marshmallow Handjee            0.000000             -3.206529   \n",
       "SR-71                          0.000000             -3.449465   \n",
       "\n",
       "                     Recommendation_Score_Spacy  \n",
       "product_name_x                                   \n",
       "Headroom                               4.856284  \n",
       "Pirate Bomb!                           4.019034  \n",
       "Fou' Foune                             3.751929  \n",
       "Abraxas                                3.279064  \n",
       "Stickee Monkee                         2.665019  \n",
       "...                                         ...  \n",
       "Assassin                              -2.782919  \n",
       "Resolute - Coconut                    -2.824905  \n",
       "Pliny The Elder                       -3.607345  \n",
       "Marshmallow Handjee                   -3.691288  \n",
       "SR-71                                 -5.085911  \n",
       "\n",
       "[250 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add spacy_similarity to df grouped by beer\n",
    "all_recs_by_beer['spacy_similarity'] = spacy_by_beer\n",
    "all_recs_by_beer['Recommendation_Score_Spacy'] = scale(spacy_by_beer) + scale(all_recs_by_beer['overall_sent_score'])\n",
    "\n",
    "# sort by recommendation score calculated using Spacy instead of BoW cosine similarity\n",
    "add_spacy = all_recs_by_beer.sort_values(by='Recommendation_Score_Spacy', ascending=False)\n",
    "result_F = add_spacy[['similarity_score','spacy_similarity','user_rating','overall_sent_score','Recommendation_Score','Recommendation_Score_Spacy']]\n",
    "result_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>spacy_similarity</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>overall_sent_score</th>\n",
       "      <th>Recommendation_Score</th>\n",
       "      <th>Recommendation_Score_Spacy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_name_x</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Headroom</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689513</td>\n",
       "      <td>4.5168</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>2.601863</td>\n",
       "      <td>4.856284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pirate Bomb!</td>\n",
       "      <td>0.010105</td>\n",
       "      <td>0.689698</td>\n",
       "      <td>4.4632</td>\n",
       "      <td>0.649175</td>\n",
       "      <td>3.300493</td>\n",
       "      <td>4.019034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fou' Foune</td>\n",
       "      <td>0.020253</td>\n",
       "      <td>0.712967</td>\n",
       "      <td>4.5068</td>\n",
       "      <td>0.496250</td>\n",
       "      <td>3.570030</td>\n",
       "      <td>3.751929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                similarity_score  spacy_similarity  user_rating  \\\n",
       "product_name_x                                                    \n",
       "Headroom                0.000000          0.689513       4.5168   \n",
       "Pirate Bomb!            0.010105          0.689698       4.4632   \n",
       "Fou' Foune              0.020253          0.712967       4.5068   \n",
       "\n",
       "                overall_sent_score  Recommendation_Score  \\\n",
       "product_name_x                                             \n",
       "Headroom                  0.750100              2.601863   \n",
       "Pirate Bomb!              0.649175              3.300493   \n",
       "Fou' Foune                0.496250              3.570030   \n",
       "\n",
       "                Recommendation_Score_Spacy  \n",
       "product_name_x                              \n",
       "Headroom                          4.856284  \n",
       "Pirate Bomb!                      4.019034  \n",
       "Fou' Foune                        3.751929  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_F[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "similarity_score              0.038135\n",
       "spacy_similarity              0.728832\n",
       "user_rating                   4.475600\n",
       "overall_sent_score            0.179663\n",
       "Recommendation_Score          3.650484\n",
       "Recommendation_Score_Spacy    1.791510\n",
       "Name: Leche Borracho, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_F.loc['Leche Borracho'] # no longer in top 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using spaCy similarity in place of BoW cosine similarity, we found that two of our original top three recommendations were replaced with other beer brands. This is likely because bag of words is more particular about finding the exact attribute whereas spaCy might assume attributes that are often mentioned together are similar when they are in fact distinct - like spicy and aroma. For instance, one of our original top three beers, Leche Borracho, included many reviews that mentioned all three attributes. However, phrases like \"spicy aroma\" were mentioned, the occurrence of which vanilla cosine similarity would have awarded a much higher similarity score compared to that from spaCy. As a result, the similarity score contribution (after scaling) to the overall recommendation score for Leche Borracho using spaCy is reduced compared to that from BoW because these two attributes are considered similar and not distinct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task G\n",
    "How would our recommendations differ if we ignored similarity and feature sentiment scores? Below backs up our conclusion with analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>spacy_similarity</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>overall_sent_score</th>\n",
       "      <th>Recommendation_Score</th>\n",
       "      <th>Recommendation_Score_Spacy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_name_x</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Chemtrailmix</td>\n",
       "      <td>0.013779</td>\n",
       "      <td>0.684733</td>\n",
       "      <td>4.754286</td>\n",
       "      <td>0.01032</td>\n",
       "      <td>-1.488965</td>\n",
       "      <td>-1.547994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>It Was All A Dream</td>\n",
       "      <td>0.014934</td>\n",
       "      <td>0.669450</td>\n",
       "      <td>4.747200</td>\n",
       "      <td>0.20800</td>\n",
       "      <td>0.343101</td>\n",
       "      <td>-0.558097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SR-71</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.605507</td>\n",
       "      <td>4.746400</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-3.449465</td>\n",
       "      <td>-5.085911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    similarity_score  spacy_similarity  user_rating  \\\n",
       "product_name_x                                                        \n",
       "Chemtrailmix                0.013779          0.684733     4.754286   \n",
       "It Was All A Dream          0.014934          0.669450     4.747200   \n",
       "SR-71                       0.001513          0.605507     4.746400   \n",
       "\n",
       "                    overall_sent_score  Recommendation_Score  \\\n",
       "product_name_x                                                 \n",
       "Chemtrailmix                   0.01032             -1.488965   \n",
       "It Was All A Dream             0.20800              0.343101   \n",
       "SR-71                          0.00000             -3.449465   \n",
       "\n",
       "                    Recommendation_Score_Spacy  \n",
       "product_name_x                                  \n",
       "Chemtrailmix                         -1.547994  \n",
       "It Was All A Dream                   -0.558097  \n",
       "SR-71                                -5.085911  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_F.sort_values(by='user_rating', ascending = False)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just return the top three rated beers in the dataset, we see the three most highly rated beers among users, irrespective of specific attributes. The point of a recommendation system is to make meaniningful suggestions to a user based on their preferences; returning the three most highly rated overall defeats that purpose. Had we not analyzed the beers using cosine similarity or spacy similarity, and simply returned the most popular beers, we would have simply given the user a list of three beers that other people found good, for reasons wholly unrelated to their preferences. That would lead the user to likely not use the recommendation system again. It's essentially a coin toss as to whether they will like the beer given to them and that is not sufficient. A good recommendation system should take the attributes from the user as inputs, then find the beers most closely associated with those attributes, so the user has the opportunity to try a beer that they are likely to enjoy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
